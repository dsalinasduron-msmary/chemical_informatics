{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7980f6-f313-4083-a270-0dc01696e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/ubuntu/.local/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/ubuntu/.local/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw, PyMol, rdFMCS\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import rdBase\n",
    "from deepchem import metrics\n",
    "from IPython.display import Image, display\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use SQL query to retrieve compounds for specified target\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import text\n",
    "\n",
    "config = dotenv_values('database_url.env')\n",
    "url = config['DATABASE_URL']\n",
    "\n",
    "engine = create_engine(url, echo=False)\n",
    "#target_id = 'ENSG00000120217'\n",
    "target_id = 'ENSG00000198900'\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    query = text(\"SELECT * FROM target_to_compounds WHERE target_ensemble_id='{target}';\".format(target=target_id))\n",
    "    target_to_compounds_df = pd.read_sql(query, conn)\n",
    "\n",
    "#display(target_to_compounds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_dataset = target_to_compounds_df\n",
    "smiles = compound_dataset['smiles']\n",
    "\n",
    "IC50 = compound_dataset['standard_value']\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "compound_dataset['featurized'] = featurizer.featurize(smiles)\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation = True)\n",
    "compound_dataset['frag_featurized'] = featurizer.featurize(smiles)\n",
    "compound_dataset['divided values'] = compound_dataset['standard_value'].astype(float).div(108000)\n",
    "compound_dataset['pIC50'] = np.log10(compound_dataset['divided values'].astype(float)).mul(-1)\n",
    "compound_dataset['number'] = list(range(0,len(compound_dataset)))\n",
    "#display(compound_dataset.head(5))\n",
    "\n",
    "training_dataset = compound_dataset.sample(frac = 0.7)\n",
    "\n",
    "#training_dataset.featurized[0].n_feat\n",
    "\n",
    "testing_dataset = (compound_dataset[~compound_dataset['number'].isin(training_dataset['number'])])\n",
    "\n",
    "\n",
    "numpy_training_dataset = dc.data.NumpyDataset(X=training_dataset['featurized'],y=training_dataset['pIC50'].astype(float), ids=training_dataset['smiles'])\n",
    "numpy_testing_dataset = dc.data.NumpyDataset(X=testing_dataset['featurized'],y=testing_dataset['pIC50'].astype(float), ids=testing_dataset['smiles'])\n",
    "\n",
    "mols = [m for m in Chem.SmilesMolSupplier('smiles.csv', ',') if m is not None]\n",
    "dataset = numpy_testing_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca453f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compound_dataset['smi_to_mol'] = Chem.SmilesMolSupplierFromText(compound_dataset['smiles'].values.tolist())\n",
    "#pd.DataFrame.to_csv(compound_dataset)\n",
    "just_smiles_df = pd.DataFrame()\n",
    "#just_smiles_df['smiles'] = compound_dataset['smiles']\n",
    "just_smiles_df['smiles'] = testing_dataset['smiles']\n",
    "smiles = just_smiles_df['smiles'].tolist()\n",
    "#just_smiles_df['name'] = [-1 for thing in smiles]\n",
    "just_smiles_df['name'] = just_smiles_df['smiles']\n",
    "#print(just_smiles_df)\n",
    "just_smiles_df.to_csv('smiles.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018964ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2, dense_layer_size=10)\n",
    "model.fit(numpy_training_dataset, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = numpy_testing_dataset\n",
    "pred = model.predict(test_dataset)\n",
    "print(test_dataset.y)\n",
    "print(pred)\n",
    "mse = metrics.mean_squared_error(y_true=test_dataset.y, y_pred=pred)\n",
    "r2 = metrics.r2_score(y_true=test_dataset.y, y_pred=pred)\n",
    "print(mse)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f378f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_dataset = dc.data.NumpyDataset(X=testing_dataset['frag_featurized'], y = None, w = None, ids = test_dataset.ids)\n",
    "print(frag_dataset.get_shape)\n",
    "tr = dc.trans.FlatteningTransformer(frag_dataset) # flatten dataset and add ids to each fragment\n",
    "frag_dataset = tr.transform(frag_dataset)\n",
    "print(frag_dataset.get_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97445e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole molecules\n",
    "pred = model.predict(test_dataset)\n",
    "pred = pd.DataFrame(pred, index=test_dataset.ids, columns=[\"Molecule\"])  # turn to dataframe for convenience\n",
    "display(pred)\n",
    "# fragments\n",
    "pred_frags = model.predict(frag_dataset)\n",
    "pred_frags = pd.DataFrame(pred_frags, index=frag_dataset.ids, columns=[\"Fragment\"])  # turn to dataframe for convenience\n",
    "#pred_frags = pd.DataFrame(pred_frags,index=range(0, len(frag_dataset)), columns=[\"Fragment\"])\n",
    "print(pred_frags)\n",
    "# merge 2 dataframes by molecule names\n",
    "df = pd.merge(pred_frags, pred, right_index=True, left_index=True)\n",
    "# find contribs\n",
    "df['Contrib'] = df[\"Molecule\"] - df[\"Fragment\"]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for molecule in pred.index:\n",
    "    print('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/{molecule}/PNG'.format(molecule=molecule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_contribs(mols, df, smi_or_sdf = \"smi\"): \n",
    "    # input format of file, which was used to create dataset determines the order of atoms, \n",
    "    # so we take it into account for correct mapping!\n",
    "    maps = []\n",
    "    for mol  in mols:\n",
    "        wt = {}\n",
    "        if smi_or_sdf == \"smi\":\n",
    "            for n,atom in enumerate(Chem.rdmolfiles.CanonicalRankAtoms(mol)):\n",
    "                wt[atom] = df.loc[mol.GetProp(\"_Name\"),\"Contrib\"][n]\n",
    "\n",
    "        if smi_or_sdf == \"sdf\":        \n",
    "            for n,atom in enumerate(range(mol.GetNumHeavyAtoms())):\n",
    "                wt[atom] = df.loc[Chem.MolToSmiles(mol),\"Contrib\"][n]\n",
    "        maps.append(SimilarityMaps.GetSimilarityMapFromWeights(mol,wt))\n",
    "    return maps    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_contribs(mols, df, 'smi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
